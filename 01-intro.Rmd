# Introduction {#intro}

## Motivation and Objectives

<!-- REPRESENTATIONS -->
<!-- - temporal representations: zum Beispiel CBMS2015 -->
<!-- - representation learning -> move auf derived/ -->
<!-- embedded feature space -->

<!-- methods and applications, workflows -->
<!-- show variety of medical applications -->
<!-- - subpopulation-specific analysiss -->

Common objectives of data analysis in medical research include (i) identifying long-term determinants and protective factors of a medical condition of interest, (ii) discovering subpopulations with increased outcome prevalence, and (iii) generating robust statistical models that can explain relationships between one or more independent variables and the target variable. 
For example, epidemiologists attempt to discover associations between multiple risk factors and an outcome in cohort studies by collecting data that include extensive information about participants obtained from questionnaires, medical examinations, laboratory analyses, and imaging. 
Often these data are collected repeatedly over time, for example in longitudinal studies. 
This means that there is latent but often overlooked temporal information in such data, the investigation of which can potentially lead to new insights.

To find associations between variables, medical researchers usually first carefully derive some hypotheses from clinical practice, experimental studies, or extensive literature reviews to then test them formally for statistical significance. 
However, with the ever-increasing volume and heterogeneity of medical data, traditional hypothesis-driven workflows are becoming increasingly impractical, as for this reason some important inherent associations between variables may go undetected. 
Machine learning can improve medical research by discovering understandable descriptions of patient or study participant subpopulations that are similar in outcome, and thus can be used to derive new hypotheses. 

The proliferation of medical machine learning applications is triggered by several reasons, such as the desire to make automated use of the plethora of information collected about study subjects, but sometimes just based on the ubiquity of deep learning success stories in the media. 
However, the ease of creating complex data-driven models is no guarantee that insights can be effortlessly derived. 
Most state-of-the-art machine learning algorithms such as deep neural networks and gradient boosting machines generate so-called black-box models with multiple layers of complexity that involve many multivariate, nonlinear interactions between variables that are difficult to represent intuitively. 
It is critical that the application expert, who is not a practitioner but a scientist working in a clinical or epidemiological setting, be equipped with tools to understand, explore, and visualize the models so that they can drill down to specific individual patterns and gain actionable insights that ultimately contribute to prevention, diagnosis, and treatment in clinical practice. 
Because medical data come from a wide variety of sources key characteristics of the collected datasets vary, requiring adaptation of methods to the specifics of each application scenario. 

The goal of our work is to develop methods that serve as intelligent assistance to medical researchers in the analysis of high-dimensional, temporal medical data. 
Hence, the core research question of the thesis is: How to derive accurate yet understandable patterns for subpopulation discovery in high-dimensional temporal medical data? 
Both before, during, and after the generation of machine learning models, several challenges must be overcome in order for the domain expert to be able to derive actionable knowledge. 
These challenges can be translated into the following four requirements. 
(1) _Comprehensibility of patterns_: the extracted models, including clusters, rules, and other patterns, must be made understandable; preferably, the model generation process is also comprehensible.
(2) _Exploitation of time_: latent temporal information must be exploited, while satisfying requirement 1.
<!-- Medical scholars search for long-term determinants of severe diseases. Finding patterns in the patient history and evolution can contribute to this aim. -->
(3) _Minimization of redundancy_: redundancy must be minimized, while satisfying requirement (1). 
Patterns may overlap in terms of the topics they cover. 
This leads to a redundancy of patterns, which has a negative impact on the perceived quality of the model. 
Our task is to extract, process and display the most relevant (temporal) patterns for expert-driven model exploration.

<!-- - temporal representations: zum Beispiel CBMS2015 -->
<!-- - representation learning -> move auf derived/ -->
<!-- embedded feature space -->

<!-- When tackling these requirements, the following aspects have to be dealt with: -->
<!-- (i) _Dimensionality_: to what extent can the same methods be used on low-dimensional and high-dimensional data?  -->
<!-- (ii) _Time granularity_: to what extent can the same methods be used on data with few discrete waves and with dense temporal recordings? -->
<!-- (iii) The _impact of the protocol_: to what extent can the same approaches be used both for data recorded in clinical studies to answer a small number of specific research questions and data from population-based studies with a wider scope of research questions.  -->

<!-- ## Research Questions -->

<!-- The motivation described in the previous section leads to the following research questions, including the core research question (RQ).  -->
<!-- The core research question of the thesis is: **How to derive accurate yet understandable patterns for subpopulation discovery in high-dimensional temporal medical data?**  -->
<!-- This question is central for the thesis. Since it includes multiple aspects, such as feature engineering, model learning, and post-mining steps, the question is subdivided into the following three research questions. -->


<!-- - **RQ 1**: How to leverage understandable models for high-dimensional temporal medical data? -->
<!-- - **RQ 2**: How to effectively capture and exploit implicit temporal information to improve model quality? -->
<!-- - **RQ 3**: How to extract, process and display the most relevant (temporal) patterns for expert-driven model exploration? -->

<!-- \begin{bfseries} -->
<!-- 	\begin{itemize} -->
<!-- 		\item[RQ 1] How to leverage understandable models for high-dimensional temporal medical data? -->
<!-- 		\item[RQ 2] How to effectively capture and exploit implicit temporal information to improve model quality? -->
<!-- 		\item[RQ 3] How to extract, process and display the most relevant (temporal) patterns for an efficient expert-driven model exploration? -->
<!-- 	\end{itemize} -->
<!-- \end{bfseries} -->






<!-- Table&nbsp;\@ref(tab:mapping) shows a mapping between scientific articles associated with this thesis and addressed research questions. -->

<!-- ## Epidemiological and Clinical Applications -->

<!-- **A categorization of temporal medical data.** The structure of medical data naturally depends on the study design.  -->
<!-- In this thesis proposal, medical data is categorized using the following six criteria. -->

<!-- - _Study type_: epidemiological vs. clinical -->
<!-- - _Number of variables_: number of variables, features, attributes or dimensions -->
<!-- - _Number of individuals_: number of individuals, subjects, instances, patients or study participants -->
<!-- - _Temporal horizon_: timespan from first to last assessment -->
<!-- - _Number of assessments over time_: number of repeated assessments over time -->
<!-- - _Temporal granularity_: frequency of repeated assessments -->


<!-- Table&nbsp;\@ref(tab:data) juxtaposes the five application datasets with respect to the six criteria depicted above. E = epidemiological; C = clinical. -->

<!-- &nbsp; | Study type | Number of variables | Number of individuals | Temporal horizon | Number of assessments | Temporal granularity -->
<!-- :-- | :- | :---- | :---- | :---- | :---- | :---- -->
<!-- SHIP | E | $\uparrow$ (>100)       | $\rightarrow$ (>800)  | $\uparrow$ (~15 yr)     | $\downarrow$ (3 obs.)   | $\downarrow$ (1 ass./5 yr)  -->
<!-- DFD | C | $\downarrow$ (<10)      | $\downarrow$ (<60)    | $\downarrow$ (~100 min) | $\uparrow$ (> 100 obs.) | $\uparrow$ ($\geq 3$ rec./min) -->
<!-- IAD | C | $\downarrow$ (<30)    | $\rightarrow$ (100)   | $\bullet$ (none)           | $\bullet$ (none)        | $\bullet$ (none) -->
<!-- Dan-MONICA | E | $\uparrow$ (>100) | $\rightarrow$ (>1000) | $\uparrow$ (~10 yr)     | $\downarrow$ (3 obs.)   | $\downarrow$ (1 ass./5 yr) -->
<!-- CHA | C | $\uparrow$ (>100)       | $\rightarrow$ (>1000) | $\downarrow$ (~10 days) | $\uparrow$ (> 2 obs.)   | NA -->

<!-- Table: (\#tab:data) Study dataset characteristics.  -->

## Structure and Contributions of This Thesis

<!-- • Chapter 2 presents relevant medical background information about cerebral aneurysms includ- -->
<!-- ing possible treatment options. -->
<!-- • Chapter 3 summarizes the ﬂow data generation according to simulated data. It gives an overview -->
<!-- of pertinent image and data processing steps as well as important hemodynamic attributes. -->
<!-- • Chapter 4 provides an overview of existing techniques to visualize blood ﬂow data, where the -->
<!-- approaches are classiﬁed according to a task taxonomy. -->

<!-- Based on the limitations of current visual exploration techniques for medical ﬂow data, we made -->
<!-- the following main contributions: -->
<!-- • Consistent Data Management and Guided Exploration: Until now, measured and simulated -->
<!-- ﬂow data are primarily used for research purpose. A signiﬁcant reason is the lack of a consistent -->
<!-- data management between domain experts with a different professional background as well -->

<!-- as standardized and easy-to-use exploration software with guided workﬂows and automatic -->
<!-- techniques to classify interesting features. -->
<!-- The research prototype Aneulysis [431] was developed in collaboration with our domain experts. -->
<!-- The general workﬂow, as well as the structure to manage the data, is presented in Chapter 5. -->
<!-- Besides a general concept to administrate aneurysm data, Aneulysis provides ﬁve modules for -->
<!-- visualizing the data. The ﬁrst module focuses on an automatic extraction and visualization -->
<!-- of morphological aneurysm descriptors, which is also introduced in Chapter 5. This includes -->
<!-- the automatic detection of the ostium surface separating the aneurysm from the healthy parent -->
<!-- vessel from which other essential descriptors are derived. Providing automatic measurement -->
<!-- methods leads to reproducible and less error-prone results compared to manually performed -->
<!-- measurements, where measurement deviations can signiﬁcantly inﬂuence treatment decisions. -->

This thesis presents solutions to support medical researchers in the data-driven analysis of high-dimensional, temporal medical data. 
Design decisions and developments were partly inspired by suggestions from the respective domain experts and cooperation partners, including a specialist for internal medicine, an epidemiologist with statistical expertise, a diabetes expert and three tinnitus specialists. 
The thesis is organized into three parts and ten chapters tackling the aforementioned research question and challenges. 
PART I covers methods for discovering subpopulations in high-dimensional data. 
PART II focuses specifically on temporal aspects of medical datasets and provides approaches that extract informative representations from latent temporal data. 
PART III addresses post-hoc analysis of machine learning models and includes solutions to derive model-, observation-, and subpopulation-level insights from otherwise "opaque" black boxes. 

* Chapter&nbsp;\@ref(background) (_Medical Background_) presents relevant medical background information, a brief comparison of medical study types and an overview of the case studies our solutions are tailored to.
* Chapter&nbsp;\@ref(imm) (_Interactive Discovery and Inspection of Subpopulations_) presents a workflow for the **TODO**
* Chapter&nbsp;\@ref(sdclu) (_Identifying Distinct Subpopulations_) examines redundancy in large rule sets describing subpopulations. We present a workflow that extracts a smaller number of representative rules. These rules are selected to avoid instance overlap as much as possible, thus covering different concepts in the data space. We evaluate our workflow on two samples of the longitudinal cohort study for each of two target variables, respectively.
* Chapter&nbsp;\@ref(phenotypes) (_Visual Identification of Informative Features_) describes our approach to identify distinct tinnitus phenotypes with parameter-free clustering, and presents novel visualizations to juxtapose phenotypes in a high-dimensional feature space and to explore phenotype-specific characteristics.
* Chapter&nbsp;\@ref(evo) (_Constructing Evolution Features to Capture Study Participant Change over Time_) present a framework for cohort analysis in longitudinal cohort studies which constructs "evolution features" from latent temporal information describing the change of cohort participants over time. We show that exploiting these novel features improves the generalization performance of classification models and report on results for the longitudinal cohort study.
* Chapter&nbsp;\@ref(diabfoot) (_Feature Extraction From Short Temporal Sequences for Clustering_) present an approach to build representations from short temporal sequences via clustering by the example of pressure- and posture-dependent plantar temperature and pressure in patients with diabetic foot syndrome. 
* Chapter&nbsp;\@ref(iml) (_Post-Hoc Interpretation of Classification Models_) focuses on making already learned, complex classification models understandable to the domain experts. We provide a workflow that combines classification of high-dimensional medical data and model explanation using post-hoc interpretation methods.
To this end, we use Shapely value explanations (SHAP), LASSO coefficients, and partial dependency graphs. 
Our approach delivers statistics and visualizations representing global feature importance, instance-individual feature importance, and subpopulation-specific feature importance, all of which help illuminate complex black-box machine learning models.
We report our results on three applications: (i) tinnitus-related distress in tinnitus patients, (ii) depressivity in tinnitus patients, and (iii) rupture risk in intracranial aneurysms.
* Chapter&nbsp;\@ref(gender) (_Subpopulation-Specific Learning and Post-Hoc Model Interpretation_) describes an approach that examines how subpopulations differ with respect to their most predictive characteristics in temporal data. To do so, we derive a post-hoc interpretation measure to assess the difference in association of predictors between two subpopulations. We report results for CHA on gender differences (subpopulations of female and male patients) for the two outcomes of tinnitus-related distress and depression, and the effect of treatment for both outcomes.
* Chapter&nbsp;\@ref(summary) (_Conclusion and Future Work_) concludes the thesis by giving a summary of the contributions and detailed perspectives for the presented work.

<!-- - a workflow and interactive application for data preparation, mining, and inspection of patterns for epidemiological data [@Niemann:ESWA2014; @Niemann:IMM2014], -->
<!-- - a feature engineering framework for modeling and exploitation of the cohort participant evolution over time to improve classification quality  [@Niemann:CBMS2015; @Niemann:SciRep2020], -->
<!-- - a mechanism for feature extraction from raw multi-variate time-series to identify relevant subgroups in patients and healthy controls and [@Niemann:CBMS2016; @Niemann:PONE2016], -->
<!-- - a clustering-based algorithm that hierarchically reorganizes classification rule sets and summarizes all important concepts wihle maintaining diversity between the rule clusters to reduce pattern redundancy [@Niemann:CBMS2017], -->
<!-- - a pipeline for feature extraction, classification with post-mining functionalities such as feature ranking and inspection [@Niemann:CBMS2018], and -->
<!-- - results that confirm findings from medical literature or results that can be validated in independent studies. -->


<!-- Article | **RQ1** | **RQ2** | **RQ3** | Datasets -->
<!-- :-- | :--: | :--: | :--: | :-- -->
<!-- [@Niemann:ESWA2014] | $\checkmark$ |  |  $\checkmark$ | SHIP -->
<!-- [@Niemann:IMM2014] | $\checkmark$ |  | $\checkmark$  | SHIP -->
<!-- [@NiemannEtAl:FCDS2014] | $\checkmark$ |  |   | SHIP -->
<!-- [@Niemann:CBMS2015] | $\checkmark$ | $\checkmark$ |   | SHIP -->
<!-- [@Niemann:CBMS2016] | $\checkmark$ | $\checkmark$ |   | DFD -->
<!-- [@Niemann:PONE2016] | $\checkmark$ | $\checkmark$ |   | DFD -->
<!-- [@Niemann:CBMS2017] | $\checkmark$ |  |   | SHIP -->
<!-- [@Niemann:CBMS2018] | $\checkmark$ |  |   | IAD -->
<!-- [@Niemann:EBioMedicine2020] | $\checkmark$ |  | $\checkmark$ | DFD -->
<!-- [@Niemann:SREP2020] | $\checkmark$ |  | $\checkmark$ | CHA -->
<!-- [@Niemann:PONE2020] | $\checkmark$ |  | $\checkmark$ | CHA -->
<!-- [@Niemann:Frontiers2020] | $\checkmark$ |  | $\checkmark$ | CHA -->
<!-- [@Niemann:SREP_Pheno2020] | $\checkmark$ |  | $\checkmark$ | CHA -->
<!-- [@Niemann:SciRep2020] | $\checkmark$ | $\checkmark$ |   | SHIP, MONICA -->

<!-- Table: (\#tab:mapping) Mapping of published and planned articles to research questions.  -->

