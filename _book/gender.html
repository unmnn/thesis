<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Subpopulation-Specific Learning and Post-Hoc Model Interpretation | Intelligent Assistance for Expert-Driven Subpopulation Discovery in High-Dimensional Timestamped Medical Data</title>
<meta name="author" content="Uli Niemann">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.6/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.2.9002/tabs.js"></script><script src="libs/bs3compat-0.2.2.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="font-awesome.min.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Intelligent Assistance for Expert-Driven Subpopulation Discovery in High-Dimensional Timestamped Medical Data</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome!</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="background.html"><span class="header-section-number">2</span> Medical Background and Datasets</a></li>
<li class="book-part">Subpopulation Discovery in High-Dimensional Data</li>
<li><a class="" href="imm.html"><span class="header-section-number">3</span> Interactive Discovery and Inspection of Subpopulations</a></li>
<li><a class="" href="sdclu.html"><span class="header-section-number">4</span> Identifying Distinct Subpopulations</a></li>
<li><a class="" href="phenotypes.html"><span class="header-section-number">5</span> Visual Identification of Informative Features</a></li>
<li class="book-part">EXPLOITING DYNAMICS</li>
<li><a class="" href="evo.html"><span class="header-section-number">6</span> Constructing Evolution Features to Capture Change over Time</a></li>
<li><a class="" href="diabfoot.html"><span class="header-section-number">7</span> Feature Extraction from Short Temporal Sequences for Clustering</a></li>
<li class="book-part">POST-MINING FOR INTERPRETATION</li>
<li><a class="" href="iml.html"><span class="header-section-number">8</span> Post-Hoc Interpretation of Classification Models</a></li>
<li><a class="active" href="gender.html"><span class="header-section-number">9</span> Subpopulation-Specific Learning and Post-Hoc Model Interpretation</a></li>
<li class="book-part">CONCLUSION</li>
<li><a class="" href="conclusion.html"><span class="header-section-number">10</span> Summary and Future Work</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="appx-pheno.html"><span class="header-section-number">A</span> Overview of Variables Selected for Phenotyping</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="gender" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Subpopulation-Specific Learning and Post-Hoc Model Interpretation<a class="anchor" aria-label="anchor" href="#gender"><i class="fas fa-link"></i></a>
</h1>
<div id="brief-chapter-summary-6" class="section level4 unnumbered infobox chapter-summary">
<h4>Brief Chapter Summary<a class="anchor" aria-label="anchor" href="#brief-chapter-summary-6"><i class="fas fa-link"></i></a>
</h4>
<p>We present a workflow to examine differences between <em>two</em> a priori defined subpopulations in temporal data.
For this purpose, we derive a post-hoc interpretation measure to visually assess the difference in the features’ relationship with the predicted target variable between two subpopulations.
We validate our approach on two data samples and the target variables tinnitus distress (CHA), depression (CHA), and liver fat concentration (SHIP).
We determine gender-specific differences, i.e., we separate between discriminating features (i) for both, (ii) for one of the two, and (iii) neither of the subpopulations.</p>
</div>
<div class="lit chapter-literature">
<p>This chapter is partly based on:</p>
<p>Uli Niemann, Benjamin Boecking, Petra Brueggemann, Birgit Mazurek, and Myra Spiliopoulou. “Gender-Specific Differences in Patients With Chronic Tinnitus – Baseline Characteristics and Treatment Effects.” In: <em>Frontiers in Neuroscience</em> 14 (2020), pp. 1-11. DOI: <a href="https://doi.org/10.3389%2Ffnins.2020.00487">10.3389/fnins.2020.00487</a>.</p>
</div>
<p>The previous chapter describes a workflow for the post-hoc analysis of models built on the entire population.
For several medical applications, there are either already established subpopulations that need further investigation, or it is unclear whether there are indeed differences between predefined subgroups of interest.</p>
<p>This chapter presents a workflow to explore how two disjoint subpopulations differ concerning their most predictive features.
First, we build machine learning models that separate between two subpopulations to identify informative features associated with either subpopulation.
Then, for each subpopulation separately, we train models that predict the value of a target variable.
We use a quantitative and a qualitative mechanism to compare differences in feature importance between the subpopulations.
We validate our workflow on CHA and SHIP data samples.
For CHA, we investigate questionnaire items and scores predictive of tinnitus-related distress and depression.
For SHIP, we identify variables from the baseline examinations that are potentially long-term determinants of fatty liver measured at the second follow-up ten years later.</p>
<p>This chapter is organized as follows.
In Section <a href="gender.html#gender-intro">9.1</a>, we motivate for subpopulation-specific model interpretation by discussing gender differences in tinnitus.
Section <a href="gender.html#gender-workflow">9.2</a> presents the workflow.
Section <a href="gender.html#gender-measure">9.3</a> describes the measure to quantify and visualize subpopulation-specific model differences.
Section <a href="gender.html#gender-learning-tasks">9.4</a> explains the validation setup, including learning tasks, selected learning algorithms, and dataset-specific preprocessing steps.
In Section <a href="gender.html#gender-results">9.5</a>, we report our results and main findings.
The chapter closes with a summary and a brief discussion in Section <a href="gender.html#gender-conclusion">9.6</a>.</p>
<div id="gender-intro" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Motivation and Comparison to Related Work<a class="anchor" aria-label="anchor" href="#gender-intro"><i class="fas fa-link"></i></a>
</h2>
<p>One example where the relationship between subpopulation membership on the target variable is not well understood yet is gender differences in tinnitus patients.
Female gender has been identified as an important risk factor for psychological comorbidities in many studies: women show higher prevalence rates regarding depression, anxiety, and other psychosomatic diseases <span class="citation"><a href="references.html#ref-Nolen:GenderDepression2001" role="doc-biblioref">[280]</a>–<a href="references.html#ref-Langguth:Lancet2013" role="doc-biblioref">[286]</a></span>.
However, previous studies presented conflicting results on the relationship between gender and tinnitus severity and distress.
Some studies found no gender differences with respect to tinnitus severity <span class="citation"><a href="references.html#ref-Erlandsson:Gender2001" role="doc-biblioref">[287]</a></span>, annoyance <span class="citation"><a href="references.html#ref-Pinto:Gender2010" role="doc-biblioref">[288]</a></span>, and similar tinnitus-related scores <span class="citation"><a href="references.html#ref-Meric:Gender1998" role="doc-biblioref">[289]</a></span>.
Others found higher tinnitus distress in women <span class="citation"><a href="references.html#ref-Seydel:Gender2013" role="doc-biblioref">[290]</a></span>, higher loudness and annoyance in men <span class="citation"><a href="references.html#ref-Hiller:Gender2006" role="doc-biblioref">[291]</a></span>, a high association of severe tinnitus with suicide attempts only in women <span class="citation"><a href="references.html#ref-Lugo:Sex2019" role="doc-biblioref">[292]</a></span>, and a high correlation of tinnitus severity with life quality, depression, and stress only in men <span class="citation"><a href="references.html#ref-Han:Gender2019" role="doc-biblioref">[293]</a></span>.
Overall, there is no consensus on gender-specific determinants of prevalence rates or accompanying symptoms of chronic tinnitus such as depression or anxiety.
However, gender differences in psychological response profiles and coping strategies could substantially influence tinnitus chronification and treatment success rates <span class="citation"><a href="references.html#ref-vanderwal2020" role="doc-biblioref">[294]</a></span>.
Understanding gender differences may therefore facilitate a more detailed identification of symptom profiles, increase treatment response rates, and help provide access for vulnerable populations who may be less visible in the clinical setting.</p>
</div>
<div id="gender-workflow" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Workflow<a class="anchor" aria-label="anchor" href="#gender-workflow"><i class="fas fa-link"></i></a>
</h2>
<p>We present a workflow consisting of a modeling component and a post-modeling component, extending the approach presented in Chapter <a href="iml.html#iml">8</a>.
More specifically, we (i) build machine learning models capable of predicting the values of a target variable while performing hyperparameter optimization in a cross-validation scheme, and (ii) use post-hoc interpretation mechanisms to identify variables that contributed most to the prediction of the best model.
We deviate from the workflow presented earlier because we are interested in comparing a priori defined disjoint subpopulations instead of determining them.</p>
<p>We proceed as follows.
First, we train a model for each population where subpopulation membership is the target variable.
Then, we build models for each subpopulation separately and compare model reliance values
<!-- (recall Section&nbsp;\@ref(iml-workflow-fe))  -->
between the best performing models.
More specifically, we compare which variables appear to be important (i) for both subpopulations, (ii) for one of the two subpopulations, or (iii) for neither subpopulation.
For example, we split a dataset into two non-overlapping based on the variable defining the subpopulations and validate our workflow by examining factors that discriminate between subpopulations and factors predictive for the response variable in both or either of the two subpopulations.</p>
</div>
<div id="gender-measure" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Comparing Differences in Feature Importance between Two Subpopulations<a class="anchor" aria-label="anchor" href="#gender-measure"><i class="fas fa-link"></i></a>
</h2>
<p>To measure feature-individual attributions to a model’s predictions and to compare them between two subpopulations, we use model reliance (MR; <span class="citation"><a href="references.html#ref-Fisher:ModelReliance2019" role="doc-biblioref">[258]</a></span>), which is described in the context of iterative feature elimination in Section <a href="iml.html#iml-workflow-fe">8.2.3</a>.
Recall that <span class="math inline">\(MR(f,\zeta)\)</span> is a permutation-based variable importance measure that calculates the increase in the error of a model <span class="math inline">\(\zeta\)</span> when the values of the variable of interest <span class="math inline">\(f\)</span> are randomly shuffled within the training set.
If <span class="math inline">\(f\)</span> is important for the prediction of <span class="math inline">\(\zeta\)</span>, <span class="math inline">\(MR(f,\zeta)\)</span> &gt; 1.
If random permutation of the feature values leads to a higher performance of the model, then the feature’s attribute to model quality is low, whereupon <span class="math inline">\(MR\)</span> &lt; 1.</p>
<p>For models that predict subpopulation membership, we rank features by MR value and report on the most important features.
For subpopulation-specific models, we use scatterplots (see Figure <a href="gender.html#fig:09-mr-legend">9.1</a>) depicting a feature’s contribution (as <span class="math inline">\(MR\)</span> value) to the model Model_1 (x-axis), which is trained on one subpopulation, and to the model Model_2 (y-axis), trained on the other subpopulation.
Features that contribute equally to both models are on the diagonal line, while higher <span class="math inline">\(MR\)</span> values for one model are further from the diagonal.
The variables with the highest average <span class="math inline">\(MR\)</span> score or the highest difference magnitude between subpopulation-specific <span class="math inline">\(MR\)</span> scores are colored and labeled.</p>

<div class="figure" style="text-align: center">
<span id="fig:09-mr-legend"></span>
<img src="figures/09-mr-legend.png" alt="Subpopulation-specific variable importance. The position of a point represents the model reliance score of a variable for the best model trained on the respective subpopulation, denoted as Model_1 (x-axis) and Model_2 (y-axis). Higher values represent a higher attribution of a variable relative to the model prediction. There are four characteristic areas: (i) important variables with similar attributions to Model_1 and Model_2; (ii) important variables with higher attribution to one of the subpopulation-specific models; (iii) variables important to either Model_1 or Model_2 but adversarial to the other model; (iv) variables that are adversarial to both models." width="70%"><p class="caption">
Figure 9.1: <strong>Subpopulation-specific variable importance.</strong> The position of a point represents the model reliance score of a variable for the best model trained on the respective subpopulation, denoted as Model_1 (x-axis) and Model_2 (y-axis). Higher values represent a higher attribution of a variable relative to the model prediction. There are four characteristic areas: (i) important variables with similar attributions to Model_1 and Model_2; (ii) important variables with higher attribution to one of the subpopulation-specific models; (iii) variables important to <em>either</em> Model_1 <em>or</em> Model_2 but adversarial to the other model; (iv) variables that are adversarial to both models.
</p>
</div>
</div>
<div id="gender-learning-tasks" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Learning Tasks and Evaluation Setup<a class="anchor" aria-label="anchor" href="#gender-learning-tasks"><i class="fas fa-link"></i></a>
</h2>
<p>We validate our workflow on the Charité tinnitus patient dataset (CHA, Section <a href="background.html#background-data-cha">2.2.2</a>) and the SHIP dataset (Section <a href="background.html#background-data-ship">2.2.1</a>).
We define five <em>learning tasks</em> (LT) for the following response variables and subpopulations:</p>
<!-- \begin{comment} -->
<!-- \begin{enumerate} -->
<!--   \item[\textbf{LT 1:}] gender (CHA) -->
<!--   \item[\textbf{LT 2:}] tinnitus-related distress (CHA) -->
<!--   \begin{enumerate} -->
<!--     \item[\textbf{LT 2a:}] female subpopulation -->
<!--     \item[\textbf{LT 2b:}] male subpopulation -->
<!--   \end{enumerate} -->
<!--   \item[\textbf{LT 3:}] depression (CHA) -->
<!--   \begin{enumerate} -->
<!--     \item[\textbf{LT 3a:}] female subpopulation -->
<!--     \item[\textbf{LT 3b:}] male subpopulation -->
<!--   \end{enumerate} -->
<!--   \item[\textbf{LT 4:}] gender (SHIP) -->
<!--   \item[\textbf{LT 5:}] liver fat concentration at second follow-up (SHIP) -->
<!--   \begin{enumerate} -->
<!--     \item[\textbf{LT 5a:}] female subpopulation -->
<!--     \item[\textbf{LT 5b:}] male subpopulation -->
<!--   \end{enumerate} -->
<!-- \end{enumerate} -->
<!-- \end{comment} -->
<!--  -->
<ul>
<li>LT 1: gender (CHA)</li>
<li>LT 2: tinnitus-related distress (CHA)
<ul>
<li>LT 2a: female subpopulation</li>
<li>LT 2b: male subpopulation</li>
</ul>
</li>
<li>LT 3: depression (CHA)
<ul>
<li>LT 3a: female subpopulation</li>
<li>LT 3b: male subpopulation</li>
</ul>
</li>
<li>LT 4: gender (SHIP)</li>
<li>LT 5: liver fat concentration at second follow-up (SHIP)
<ul>
<li>LT 5a: female subpopulation</li>
<li>LT 5b: male subpopulation</li>
</ul>
</li>
</ul>
<!--  --><p>LT 1 and LT 4 have gender as the target variable, and characteristics are identified that are predictive for one of the genders.
For each learning task, we use variables from the first study as predictors.
For the learning tasks LT 2, LT 3, and LT 5, we build separate models for each of the two gender subpopulations.
We refer to these models as “F_model” and “M_model,” respectively; the learning task is explicitly stated if it cannot be inferred from the context.</p>
<p><strong>Selection of algorithms and evaluation.</strong>
Based on their encouraging performances relative to other classifiers in Chapter <a href="iml.html#iml">8</a>, we use the following five algorithms:
least absolute shrinkage and selection operator (LASSO <span class="citation"><a href="references.html#ref-lasso" role="doc-biblioref">[243]</a></span>),
RIDGE <span class="citation"><a href="references.html#ref-ridge" role="doc-biblioref">[244]</a></span>, support vector machine (SVM <span class="citation"><a href="references.html#ref-Boser:SVM1992" role="doc-biblioref">[239]</a></span>), random forest (RF <span class="citation"><a href="references.html#ref-Breiman:RandomForests2001" role="doc-biblioref">[191]</a></span>) and gradient boosted trees (GBT <span class="citation"><a href="references.html#ref-Friedman:PDP2001" role="doc-biblioref">[24]</a></span>), see Section <a href="iml.html#iml-workflow-modeling">8.2.2</a> for a description.
We use 10-fold cross-validation to evaluate model generalization performance and perform a grid search for hyperparameter selection (cf. listing of parameter candidates in Table <a href="iml.html#tab:08-hyper-tab">8.1</a>).
We choose the evaluation measures based on the type of the target variable.
For LT 1, we employ accuracy and sensitivity for each gender.
For LT 2, we use root mean squared error (RMSE) and the coefficient of determination R<sup>2</sup>, defined as <span class="math inline">\(R^2=1-\frac{\sum_{i=1}^N (\hat{y}_i-y_i)^2}{\sum_{i=1}^N(\bar{y}-y_i)^2}\)</span>, where <span class="math inline">\(\bar{y}\)</span> is the average response value.
Higher values are better for all measures except RMSE.</p>
<p>For each learning task, we define a baseline performance.
For the classification problem of LT 1 and LT 4, the baseline is equal to a model that always predicts the majority class over all training observations.
Similarly, for the regression problems of LT 2, 3, and 5, the average value of a target variable over all training observations is used to predict every test instance’s response value.</p>
<p><strong>Data preparation for CHA.</strong>
For CHA, we use baseline data collected before the start of therapy.
To make the learning tasks nontrivial, we remove variables from the same questionnaire as the response variable for each task.
For example, for LT 2, we exclude all variables from the TQ questionnaire because the target variable is calculated from them.
We include 1628 patients (828 female, 800 male) with complete data for the ADSL, PSQ, SF8, SOZK, TINSKAL, TQ, and TLQ questionnaires (cf. Table <a href="background.html#tab:02-cha-questionnaires">2.1</a>).
The selection of these questionnaires is motivated to obtain a comprehensive assessment of tinnitus, comorbid conditions (e.g., depression), general quality of life, and socio-demographic data.
For CHA and SHIP, multinomial variables, i.e., variables that take three or more symbolic values, such as reported gender, marital status, and education level, are encoded as dummy variables.
For example, smoking status smoking_s0 can be one of the following values: 0 = never a smoker, 1 = ex-smoker, 2 = current smoker.
The dummy variable smoking_s0_1 then indicates whether a study participant is an ex-smoker.
To avoid multicollinearity, we remove the first dummy of each variable, leaving only n-1 dummies.
For the smoking status example, we keep smoking_s0_1 and smoking_s0_2, and we remove smoking_s0_0.
Finally, a total of 181 variables from the baseline measurements are used as predictors, including responses to individual questionnaire items, subscale scores, total scores, and, for each questionnaire, the average time taken to complete an item.
Tinnitus-related distress is measured by the TQ total score (TQ_distress).
The severity of depression is measured by the ADSL total score (ADSL_depression).</p>
<p><strong>Data preparation for SHIP.</strong>
For the SHIP data, we consider only the variables recorded in SHIP-0 and use the liver fat concentration (liverfat_s2) measured via MRT in SHIP-2.
We use the same subset of 886 labeled participants as in Chapter <a href="sdclu.html#sdclu">4</a>, of which 460 are female and 426 male.
We remove the variables related to the ultrasound diagnosis of hepatic steatosis, stea_s0 and stea_alt75_s0, because we have already identified their high correlation to the target in Chapters <a href="imm.html#imm">3</a> and <a href="sdclu.html#sdclu">4</a>.
Furthermore, we remove “near-zero” variance variables where the most frequent value occurs at least 19 times more frequently than the second most frequent value.
Typical examples include the ATC_* medication variables where few participants report taking them.
Variables with a variance near zero can lead to resampling problems because some of the resamples may have constant values for that variable.
Besides, it is difficult to infer significant correlations from them, as it is unclear whether the measured effects can be generalized to the overall population or whether they are just an artifact of this small and thus unrepresentative sample.
<!-- As an additional preprocessing step, we dummify multinomial variables, i.e., we extract multiple binary columns for variables that take three or more symbolic values.  -->
<!-- For example, smoking status smoking\_s0 can be one of the following values: 0 = never a smoker, 1 = ex-smoker, 2 = current smoker.  -->
<!-- The dummy variable smoking\_s0\_1 then indicates whether a study participant is an ex-smoker.  -->
<!-- To avoid problems related to multicollinearity in models, we remove the first dummy of each variable, leaving only n-1 dummies.  -->
<!-- For the smoking status example, we keep smoking\_s0_1 and smoking\_s0_2, and remove smoking\_s0_0. --></p>
<p>Finally, we remove highly correlated features using the algorithm of Kuhn and Johnson <span class="citation"><a href="references.html#ref-kuhn2013applied" role="doc-biblioref">[242]</a></span>.
We first compute the Pearson correlation coefficient for each pair of features.
For feature pairs with an absolute correlation value of <span class="math inline">\(r \geq\)</span> 0.9, we keep the feature that has the lower average correlation with the other features.
We repeat this process until none of the correlation values exceed the specified threshold.
Of the original 350 variables, 118 remain to be used for modeling.
Since determining the appropriate type of missingness for each variable is beyond our workflow’s scope, we assume that missingness occurs completely at random (MCAR).
Missing values are thus imputed by random sampling with replacement.</p>
</div>
<div id="gender-results" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> Validation on Two Datasets<a class="anchor" aria-label="anchor" href="#gender-results"><i class="fas fa-link"></i></a>
</h2>
<div id="results-for-cha" class="section level3" number="9.5.1">
<h3>
<span class="header-section-number">9.5.1</span> Results for CHA<a class="anchor" aria-label="anchor" href="#results-for-cha"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Distribution of the target variables.</strong>
Figure <a href="gender.html#fig:09-mr-lt23">9.4</a> shows the target variables’ distributions for the CHA learning tasks (LTs) 1-3.
There are slightly more female than male patients.
In general, female patients report higher levels of tinnitus-related distress (median ± median absolute deviation (MAD) 39.0 ± 17.8 vs. 35.5 ± 20.0) and depression (18.0 ± 11.9 vs. 14.00 ± 11.9).
TQ_distress and ADSL_depression are right-skewed in each subpopulation.
Using the TQ cutoff of 46 for tinnitus distress <span class="citation"><a href="references.html#ref-GoebelHiller:TF1998" role="doc-biblioref">[68]</a></span>, 34.1% of females and 30.8% of males show decompensated tinnitus.
Using the ADSL cutoff of 15 for depression severity <span class="citation"><a href="references.html#ref-Hautzinger:ADSL2003" role="doc-biblioref">[57]</a></span>, 57.4% of female and 45.0% of male subjects exhibit clinical depression.</p>

<div class="figure" style="text-align: center">
<span id="fig:09-targets"></span>
<img src="figures/09-targets.png" alt="Distribution of target variables (LT 1-3). For the numerical targets, median, median absolute deviation (MAD), and non-parametric 95% confidence interval (CI) using bootstrap sampling [295] with 2000 samples are presented." width="100%"><p class="caption">
Figure 9.2: <strong>Distribution of target variables (LT 1-3)</strong>. For the numerical targets, median, median absolute deviation (MAD), and non-parametric 95% confidence interval (CI) using bootstrap sampling <span class="citation"><a href="references.html#ref-DiCissio:Bootstrap1996" role="doc-biblioref">[295]</a></span> with 2000 samples are presented.
</p>
</div>
<p>Tables <a href="gender.html#tab:09-performance-1">9.1</a>-<a href="gender.html#tab:09-performance-5">9.5</a> provide an overview of the generalization performances of each method for each learning task.</p>

<div class="inline-table"><table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'>
<caption>
<span id="tab:09-performance-1">Table 9.1: </span><strong>Classifier performance (LT 1).</strong> Performance values are cross-validation mean ± standard deviation. The best performance for each measure is highlighted in bold. Sens. = Sensitivity.
</caption>
<thead><tr>
<th style="text-align:left;font-weight: bold;">
Algorithm
</th>
<th style="text-align:right;font-weight: bold;">
Accuracy (%)
</th>
<th style="text-align:right;font-weight: bold;">
Sens. female (%)
</th>
<th style="text-align:right;font-weight: bold;">
Sens. male (%)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
LASSO
</td>
<td style="text-align:right;">
71.3 ± 3.0
</td>
<td style="text-align:right;">
69.5 ± 4.2
</td>
<td style="text-align:right;">
<b>73.2 ± 4.9</b>
</td>
</tr>
<tr>
<td style="text-align:left;">
Ridge
</td>
<td style="text-align:right;">
<b>72.2 ± 2.9</b>
</td>
<td style="text-align:right;">
<b>71.4 ± 5.5</b>
</td>
<td style="text-align:right;">
73.0 ± 4.3
</td>
</tr>
<tr>
<td style="text-align:left;">
SVM
</td>
<td style="text-align:right;">
71.8 ± 3.7
</td>
<td style="text-align:right;">
70.9 ± 5.2
</td>
<td style="text-align:right;">
72.7 ± 6.0
</td>
</tr>
<tr>
<td style="text-align:left;">
RF
</td>
<td style="text-align:right;">
68.6 ± 5.2
</td>
<td style="text-align:right;">
68.7 ± 6.0
</td>
<td style="text-align:right;">
68.6 ± 7.1
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 1px solid #cdd0d4;">
GBT
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
70.4 ± 3.4
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
70.9 ± 5.1
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
69.7 ± 6.2
</td>
</tr>
<tr>
<td style="text-align:left;font-style: italic;">
Baseline
</td>
<td style="text-align:right;font-style: italic;">
50.9 ± 2.9
</td>
<td style="text-align:right;font-style: italic;">
100.0 ± 0.0
</td>
<td style="text-align:right;font-style: italic;">
0.0 ± 0.0
</td>
</tr>
</tbody>
</table></div>
<p><strong>Learning task 1 (CHA, gender classification).</strong>
Ridge achieves best cross-validation accuracy (mean: 72.2% ± standard deviation: 2.9%) with a sensitivity of 71.4% ± 5.5% for female patients and 73.0 ± 4.3% for male patients.
Figure <a href="gender.html#fig:09-lt1-imp-features">9.3</a> illustrates the item response frequencies for the variables among the top 5% with respect to model reliance (MR), i.e., the 8 variables with the highest attribution to the model prediction.
For each variable, the horizontal legend shows the corresponding text of the questionnaire item.
The vertical axis shows the responses to that item, and the horizontal axis depicts the relative frequency by gender.
These frequencies are shown as bars, red-violet for female patients and blue for male patients.
A difference in the length of the two bars for the same answer means that the percentage of giving that response is different for each gender; thus, the variable is contributing to class separation.</p>
<p>The item ADSL_adsl17 (Figure <a href="gender.html#fig:09-lt1-imp-features">9.3</a> (a)) is the most discriminating variable for the model (MR = 1.167): while 16% of female patients report having had crying spells either “mostly” or “occasionally” in the past week, only 4% of male patients do; they predominantly give the answer “rarely” (86.2%).
Female patients tend to express higher levels of worry (see Figures <a href="gender.html#fig:09-lt1-imp-features">9.3</a> (b) and <a href="gender.html#fig:09-lt1-imp-features">9.3</a> (f)) and subjective stress (see Figure <a href="gender.html#fig:09-lt1-imp-features">9.3</a> (h)).
Besides, there are gender-differences in tinnitus quality: More than half (52.4%) of all male patients report the tinnitus sound (MR = 1.056) as “whistling,” which is substantially more frequent than in female patients (35.6%), who describe their tinnitus as “rustling” noise more often (33.3%) than male patients (22.9%).</p>

<div class="figure" style="text-align: center">
<span id="fig:09-lt1-imp-features"></span>
<img src="figures/09-lt1-imp-features.png" alt="Top 8 variables on gender (LT 1). Gender-specific item response frequencies for the top 5% variables with the highest attribution towards model prediction according to model reliance (MR)." width="100%"><p class="caption">
Figure 9.3: <strong>Top 8 variables on gender (LT 1).</strong> Gender-specific item response frequencies for the top 5% variables with the highest attribution towards model prediction according to model reliance (MR).
</p>
</div>
<!-- \subsection{Learning task 2: variables measuring depression, sleep problems, tinnitus frequency and loudness were associated with tinnitus-related distress in both genders (RQ3)} -->
<p><strong>Learning task 2 (CHA, tinnitus distress prediction).</strong>
For LT 2, we ran the five algorithms once for the female patients (LT 2a) and once for the male patients (LT 2b).
Table <a href="gender.html#tab:09-performance-2">9.2</a> shows RMSE and R<sup>2</sup> for each algorithm.
For both LT 2a and LT 2b, GBT exhibits the best performance in terms of RMSE (LT 2a: 10.92 ± 0.68, LT 2b: 10.11 ± 1.12) and R<sup>2</sup> (LT 2a: 0.55 ± 0.04, LT 2b: 0.68 ± 0.06).
It is noticeable that GBT and the other models are slightly more accurate for male patients than for females.
The highest MR feature attribution is achieved by TINSKAL_impairment, i.e., the TINSKAL visual analog scale for tinnitus impairment.
Figure <a href="gender.html#fig:09-mr-lt23">9.4</a> (a) illustrates that MR scores are higher for male patients (MR = 1.42 vs. 1.24).
Furthermore, the variables ADSL_depression (depression), ADSL_adsl11 (sleep problems), and TINSKAL_loudness (tinnitus loudness) appear to be important for both models.
It is noteworthy that the MR scores of most of the 120 variables are close to 1, which is visualized by the clump of points in Figure <a href="gender.html#fig:09-mr-lt23">9.4</a> (a).
In fact, only 8 variables exhibit a substantial attribution with MR &gt; 1.05 for either of the gender-specific models.</p>

<div class="inline-table"><table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'>
<caption>
<span id="tab:09-performance-2">Table 9.2: </span><strong>Regression model performance (LT 2a, LT 2b).</strong> Performance values are cross-validation mean ± standard deviation. The best performance for each measure is highlighted in bold.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
LT 2a (female)
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
LT 2b (male)
</div>
</th>
</tr>
<tr>
<th style="text-align:left;font-weight: bold;">
Algorithm
</th>
<th style="text-align:right;font-weight: bold;">
RMSE
</th>
<th style="text-align:right;font-weight: bold;">
R²
</th>
<th style="text-align:right;font-weight: bold;">
RMSE
</th>
<th style="text-align:right;font-weight: bold;">
R²
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
LASSO
</td>
<td style="text-align:right;">
11.55 ± 0.70
</td>
<td style="text-align:right;">
0.50 ± 0.04
</td>
<td style="text-align:right;">
10.59 ± 0.98
</td>
<td style="text-align:right;">
0.65 ± 0.05
</td>
</tr>
<tr>
<td style="text-align:left;">
Ridge
</td>
<td style="text-align:right;">
11.59 ± 0.63
</td>
<td style="text-align:right;">
0.50 ± 0.04
</td>
<td style="text-align:right;">
10.72 ± 1.05
</td>
<td style="text-align:right;">
0.64 ± 0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
SVM
</td>
<td style="text-align:right;">
11.97 ± 0.51
</td>
<td style="text-align:right;">
0.46 ± 0.03
</td>
<td style="text-align:right;">
11.21 ± 1.02
</td>
<td style="text-align:right;">
0.61 ± 0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
RF
</td>
<td style="text-align:right;">
11.38 ± 0.74
</td>
<td style="text-align:right;">
0.51 ± 0.05
</td>
<td style="text-align:right;">
10.58 ± 1.01
</td>
<td style="text-align:right;">
0.65 ± 0.06
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 1px solid #cdd0d4;">
GBT
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>10.92 ± 0.68</b>
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>0.55 ± 0.04</b>
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>10.11 ± 1.12</b>
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>0.68 ± 0.06</b>
</td>
</tr>
<tr>
<td style="text-align:left;font-style: italic;">
Baseline
</td>
<td style="text-align:right;font-style: italic;">
16.22 ± 1.38
</td>
<td style="text-align:right;font-style: italic;">
0.00 ± 0.00
</td>
<td style="text-align:right;font-style: italic;">
17.77 ± 1.00
</td>
<td style="text-align:right;font-style: italic;">
0.00 ± 0.00
</td>
</tr>
</tbody>
</table></div>
<div class="figure" style="text-align: center">
<span id="fig:09-mr-lt23"></span>
<img src="figures/09-mr-lt23.png" alt="Juxtaposition of variable importance (LT 2 and LT 3). Each scatterplot shows the model reliance (MR) score for each predictor for the best model for each of the subpopulations of female (x-axis) and male (y-axis) patients and for each learning task; see Figure 9.1. Variables among the top 10 highest-ranking variables by MR in the F_model (red-violet), M_model (blue), or both models (yellow) are highlighted. (a) LT 2 (CHA, response: tinnitus-related distress); (b) LT 3 (CHA, response: depression severity)." width="100%"><p class="caption">
Figure 9.4: <strong>Juxtaposition of variable importance (LT 2 and LT 3)</strong>. Each scatterplot shows the model reliance (MR) score for each predictor for the best model for each of the subpopulations of female (x-axis) and male (y-axis) patients and for each learning task; see Figure <a href="gender.html#fig:09-mr-legend">9.1</a>. Variables among the top 10 highest-ranking variables by MR in the F_model (red-violet), M_model (blue), or both models (yellow) are highlighted. (a) LT 2 (CHA, response: tinnitus-related distress); (b) LT 3 (CHA, response: depression severity).
</p>
</div>
<!-- \subsection{Learning task 3: indicators of mental health, stress and worries associated with depression in both genders (RQ3)} -->
<p><strong>Learning task 3 (CHA, depression prediction).</strong>
For depression severity, LASSO provides the best model for both female patients (RMSE = 5.80 ± 0.73; R<sup>2</sup> = 0.74 ± 0.06) and male patients (RMSE = 5.10 ± 0.38; R<sup>2</sup> = 0.81 ± 0.03), as depicted in Table <a href="gender.html#tab:09-performance-3">9.3</a>.
Similar to LT2, the RMSE and R<sup>2</sup> estimates for the models are consistently better for the subgroup of male patients.
Figure <a href="gender.html#fig:09-mr-lt23">9.4</a> (b) shows that the mental health indicator SF8_mentalhealth is the most important predictor for both the F_model and the M_model.
Furthermore, features measuring subjective stress (PSQ_stress05: <em>“You feel lonely or isolated.”</em>), worry (PSQ_worries score), and vitality (SF8_sf05: <em>“How much energy have you had in the last 4 weeks?”</em>) contribute substantially to the predictions of both genders’ models.</p>

<div class="inline-table"><table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'>
<caption>
<span id="tab:09-performance-3">Table 9.3: </span><strong>Regression model performance (LT 3a, LT 3b).</strong> Performance values are cross-validation mean ± standard deviation. The best performance for each measure is highlighted in bold.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
LT 3a (female)
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
LT 3b (male)
</div>
</th>
</tr>
<tr>
<th style="text-align:left;font-weight: bold;">
Algorithm
</th>
<th style="text-align:right;font-weight: bold;">
RMSE
</th>
<th style="text-align:right;font-weight: bold;">
R²
</th>
<th style="text-align:right;font-weight: bold;">
RMSE
</th>
<th style="text-align:right;font-weight: bold;">
R²
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
LASSO
</td>
<td style="text-align:right;">
<b>5.80 ± 0.73</b>
</td>
<td style="text-align:right;">
<b>0.74 ± 0.06</b>
</td>
<td style="text-align:right;">
<b>5.10 ± 0.38</b>
</td>
<td style="text-align:right;">
<b>0.81 ± 0.03</b>
</td>
</tr>
<tr>
<td style="text-align:left;">
Ridge
</td>
<td style="text-align:right;">
5.88 ± 0.65
</td>
<td style="text-align:right;">
<b>0.74 ± 0.06</b>
</td>
<td style="text-align:right;">
5.14 ± 0.38
</td>
<td style="text-align:right;">
0.80 ± 0.03
</td>
</tr>
<tr>
<td style="text-align:left;">
SVM
</td>
<td style="text-align:right;">
6.12 ± 0.72
</td>
<td style="text-align:right;">
0.71 ± 0.06
</td>
<td style="text-align:right;">
5.29 ± 0.38
</td>
<td style="text-align:right;">
0.79 ± 0.03
</td>
</tr>
<tr>
<td style="text-align:left;">
RF
</td>
<td style="text-align:right;">
6.02 ± 0.62
</td>
<td style="text-align:right;">
0.72 ± 0.05
</td>
<td style="text-align:right;">
5.29 ± 0.46
</td>
<td style="text-align:right;">
0.79 ± 0.04
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 1px solid #cdd0d4;">
GBT
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
6.10 ± 0.65
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
0.72 ± 0.06
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
5.16 ± 0.42
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
0.80 ± 0.04
</td>
</tr>
<tr>
<td style="text-align:left;font-style: italic;">
Baseline
</td>
<td style="text-align:right;font-style: italic;">
11.36 ± 0.78
</td>
<td style="text-align:right;font-style: italic;">
0.00 ± 0.00
</td>
<td style="text-align:right;font-style: italic;">
11.52 ± 0.47
</td>
<td style="text-align:right;font-style: italic;">
0.00 ± 0.00
</td>
</tr>
</tbody>
</table></div>
<!-- While all models of LT 1, 2a, 2b, 3a and 3b outperformed the baselines, neither of the models predicting the treatment effect of tinnitus-related distress (LT4a and LT4b) or depression (LT5a and LT5b) was significantly better than the baselines. -->
</div>
<div id="results-for-ship" class="section level3" number="9.5.2">
<h3>
<span class="header-section-number">9.5.2</span> Results for SHIP<a class="anchor" aria-label="anchor" href="#results-for-ship"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Learning task 4 (SHIP, gender classification).</strong>
Table <a href="gender.html#tab:09-performance-4">9.4</a> shows that LASSO performs best in terms of accuracy (99.4% ± 0.8%) and sensitivity for the male class (99.5% ± 1.0%), while GBT achieves the highest sensitivity for the female class (99.6% ± 0.9%).
All regression models outperform the baseline, which constantly predicts the female majority class (51.9% ± 4.8%).
Figure <a href="gender.html#fig:09-lt4-imp-features">9.5</a> depicts the distributions of the 4 features with an MR score of at least 1.05 for the LASSO model.
The two anthropometric measures, waist circumference (som_tail_s0) and hip circumference (som_huef_s0), appear to be predictive of the gender of the study participant.
From Figure <a href="gender.html#fig:09-lt4-imp-features">9.5</a> (a), it can be inferred that, in general, men have a higher waist circumference than women (median: 92.2 cm vs. 77.5 cm).
While the median hip circumferences are similar (f: 99.8 cm, m: 100.0 cm), it can be seen in Figure <a href="gender.html#fig:09-lt4-imp-features">9.5</a> (d) that the distribution of women has a wider spread and more values beyond the distribution tails of men, i.e., values below 86 cm and above 123 cm.
The second most important feature, gfr_mdrd_s0, is the glomerular filtration rate, a measure of overall renal function that describes the flow rate of filtered fluid through the kidney.
Figure <a href="gender.html#fig:09-lt4-imp-features">9.5</a> (b) shows that gfr_mdrd_s0 is generally higher in men, consistent with the literature <span class="citation"><a href="references.html#ref-hannemann2012age" role="doc-biblioref">[296]</a></span>.
The third most important feature, crea_s_s0 (Figure <a href="gender.html#fig:09-lt4-imp-features">9.5</a> (c)), measures serum creatinine concentration, another indicator of renal function, which is higher in men <span class="citation"><a href="references.html#ref-crea" role="doc-biblioref">[297]</a></span>.</p>

<!-- Asterisks signify models with significantly better cross-validation performance compared to the baseline with respect to accuracy using independent right-tailed Student's t-test with \[\alpha\] = 0.05. -->
<!-- using independent one-tailed Student's t-test (right-tailed for accuracy; left-tailed for RMSE) -->
<div class="inline-table"><table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'>
<caption>
<span id="tab:09-performance-4">Table 9.4: </span><strong>Classifier performance (LT 4).</strong> Performance values are cross-validation mean ± standard deviation. The best performance for each measure is highlighted in bold. Sens. = Sensitivity.
</caption>
<thead><tr>
<th style="text-align:left;font-weight: bold;">
Algorithm
</th>
<th style="text-align:right;font-weight: bold;">
Accuracy (%)
</th>
<th style="text-align:right;font-weight: bold;">
Sens. female (%)
</th>
<th style="text-align:right;font-weight: bold;">
Sens. male (%)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
LASSO
</td>
<td style="text-align:right;">
<b>99.4 ± 0.8</b>
</td>
<td style="text-align:right;">
99.4 ± 1.0
</td>
<td style="text-align:right;">
<b>99.5 ± 1.0</b>
</td>
</tr>
<tr>
<td style="text-align:left;">
Ridge
</td>
<td style="text-align:right;">
98.2 ± 1.9
</td>
<td style="text-align:right;">
98.1 ± 2.0
</td>
<td style="text-align:right;">
98.3 ± 2.3
</td>
</tr>
<tr>
<td style="text-align:left;">
SVM
</td>
<td style="text-align:right;">
99.1 ± 0.9
</td>
<td style="text-align:right;">
98.9 ± 1.1
</td>
<td style="text-align:right;">
99.3 ± 1.2
</td>
</tr>
<tr>
<td style="text-align:left;">
RF
</td>
<td style="text-align:right;">
96.6 ± 2.5
</td>
<td style="text-align:right;">
98.3 ± 1.9
</td>
<td style="text-align:right;">
94.9 ± 4.1
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 1px solid #cdd0d4;">
GBT
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
99.3 ± 0.8
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>99.6 ± 0.9</b>
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
99.1 ± 1.2
</td>
</tr>
<tr>
<td style="text-align:left;font-style: italic;">
Baseline
</td>
<td style="text-align:right;font-style: italic;">
51.9 ± 4.8
</td>
<td style="text-align:right;font-style: italic;">
100.0 ± 0.0
</td>
<td style="text-align:right;font-style: italic;">
0.0 ± 0.0
</td>
</tr>
</tbody>
</table></div>
<div class="figure" style="text-align: center">
<span id="fig:09-lt4-imp-features"></span>
<img src="figures/09-lt4-imp-features.png" alt="Top 4 variables on gender (LT 4). Gender-specific item response frequencies for the 4 variables with the highest attribution towards model prediction according to model reliance (MR). For crea_s_s0, an outlier (creas_s_s0 = 281) was removed to preserve plot readability. GFR = glomerular filtration rate." width="100%"><p class="caption">
Figure 9.5: <strong>Top 4 variables on gender (LT 4).</strong> Gender-specific item response frequencies for the 4 variables with the highest attribution towards model prediction according to model reliance (MR). For crea_s_s0, an outlier (creas_s_s0 = 281) was removed to preserve plot readability. GFR = glomerular filtration rate.
</p>
</div>
<p><strong>Learning task 5 (SHIP, prediction of liver fat concentration).</strong>
The target variable liver fat_s2 is highly right-skewed in each gender subpopulation (Figure <a href="gender.html#fig:09-ship">9.6</a> (a)).
For example, whereas the lower half of the females’ distribution lies between 1.18% and 3.29%, the upper half has a much wider spread, ranging between 3.29% and 41.8%.
Males have a higher median liver fat concentration (5.57%) than females (3.29%).
In the female subpopulation (LT 5a), LASSO performs best in terms of RMSE (5.76 ± 1.05) and R<sup>2</sup> (0.23 ± 0.12), whereas GBT achieves a minimum RMSE (6.02 ± 1.11) and a maximum R<sup>2</sup> (0.20 ± 0.16) in the male subpopulation (LT 5b), see Table <a href="gender.html#tab:09-performance-5">9.5</a>.
All regression models for LT 5a outperform the baseline predicting subpopulation mean liver fat concentration.
Only SVM performs worse on the RMSE than the baseline for LT 5b.</p>
<p>Figure <a href="gender.html#fig:09-ship">9.6</a> (b) visualizes the LASSO models’ MR scores for the female and male subpopulations.
Waist circumference (som_tail_s0) and serum uric acid concentration (hrs_s_s0) are the only predictors that appear among the top 10 features in both subpopulations.
Of note, several features are considerably responsible for model predictions in one subpopulation but not the other, as illustrated by the points near the horizontal and vertical dashed lines.
Recall that these lines indicate MR = 1, which expresses that a feature neither contributes to nor hinders model performance.</p>
<p>Waist circumference (som_tail_s0) and serum uric acid concentration (hrs_s_s0) are the only predictors that appear among the top 10 features in both subpopulations.
The feature metabolic syndrome (metsyn_s0_1) appears to be predictive only for the female subpopulation.
Indeed, the Pearson point biserial correlation of metsyn_s0_1 and liverfat_s2 is <span class="math inline">\(r\)</span> = 0.44 for the female subpopulation, which is considerably larger than for the male subpopulation, where <span class="math inline">\(r\)</span> = 0.22.
Similarly, the feature alat_s_s0, which measures alanine aminotransferase (ALAT) concentration, is more informative of liver fat concentration in the male subpopulation (<span class="math inline">\(r\)</span> = 0.38 in men vs <span class="math inline">\(r\)</span> = 0.16 in women).
Furthermore, important characteristics for women are increased waist circumference categorization (waiidf_s0_1; waist circumference <span class="math inline">\(\geq\)</span> 80 cm; cutoff is 94 cm for men), serum triglyceride concentration (tq_s_s0), heart rate (heartr_s0), sleep problems (sleepp_s0_1), waist-to-hip ratio (whratc_s0_1), antihypertensive medication (antihyp_s0_1), and ferritin concentration (ferri_s0).
In men, other features with the highest model attribution include restless legs syndrome (rlegs_s0_1), serum creatinine concentration (crea_s0_s0), body mass index (som_bmi_s0), diastolic blood pressure (diabp_s0), smoking status (smoking_s0_1), the genetic marker rs11597086 (gx_rs11597086_2) which is associated with ALAT concentration <span class="citation"><a href="references.html#ref-yuan2008population" role="doc-biblioref">[116]</a></span>, and the “SF-12 Physical and Mental Health Summary Scale” score (mcs_sf12_s0; <span class="citation"><a href="references.html#ref-bullinger1995german" role="doc-biblioref">[298]</a></span>).
In females (males), for 10 (16) of 116 features, it holds that MR <span class="math inline">\(\geq\)</span> 1. These numbers are identical to the number of features with a nonzero coefficient in the respective LASSO models.</p>
<!-- s0_Transformierte_Variablen_20150311_v06.pdf -->
<!-- ship_data_dictionary.json -->

<!-- <strong>Juxtaposition of variable importance (LT 2 and LT 3)</strong>. Each scatterplot shows the model reliance (MR) score for each predictor for the best model for each of the subpopulations of female (x-axis) and male (y-axis) patients and for each learning task; see Figure <a href="gender.html#fig:09-mr-legend">9.1</a>. Variables among the top 10 highest-ranking variables by MR in the F_model (red-violet), M_model (blue), or both models (yellow) are highlighted. (a) LT 2 (CHA, response: tinnitus-related distress); (b) LT 3 (CHA, response: depression severity). **Juxtaposition of variable importance (LT 2 and LT 3)**. Each scatterplot shows the model reliance (MR) score for each predictor for the best model for each of the subpopulations of female (x-axis) and male (y-axis) patients and for each learning task; see Figure&nbsp;\@ref(fig:09-mr-legend). Variables among the top-10 highest-ranking variables by MR in the F\_model (red-violet), M\_model (blue), or both models (yellow) are highlighted. (a) LT 1 (response: tinnitus-related distress TQ\_distress); (b) LT 2 (response: depression severity ADSL\_depression). -->
<div class="figure" style="text-align: center">
<span id="fig:09-ship"></span>
<img src="figures/09-ship.png" alt="Distribution of target variable and variable importance (LT 5). (a) Distribution of liverfat_s2 for the subset of female and male SHIP participants. (b) Each scatterplot shows the model reliance (MR) score for each predictor for the best model for each of the subpopulations of female (x-axis) and male (y-axis) patients and each learning task; see Figure 9.1. Variables among the top 10 highest-ranked variables by MR in the F_model (red-violet), M_model (blue), or both models (yellow) are highlighted. alat_s_s0: alanine aminotransferase (ALAT) concentration; antihyp_s0_1: antihypertensive medication; crea_s_s0: serum creatinine concentration; diabp_s0: diastolic blood pressure; ferri_s0: ferritin concentration; gx_rs11597086_2: genetic marker associated with ALAT concentration [116]; heartr_s0: heart rate; hrs_s_s0: serum uric acid concentration; mcs_sf12_s0: SF-12 Physical and Mental Health Summary Scale [298]; metsyn_s0_1: metabolic syndrome; rlegs_s0_1: restless legs syndrome; sleepp_s0_1: sleep problems; smoking_s0_1: ex-smoker; som_bmi_s0: body mass index; som_tail_s0: waist circumference; tg_s_s0: serum triglycerides concentration; waiidf_s0_1: increased waist circumference; whratc_s0_1: waist to hip ratio." width="100%"><p class="caption">
Figure 9.6: <strong>Distribution of target variable and variable importance (LT 5)</strong>. (a) Distribution of liverfat_s2 for the subset of female and male SHIP participants. (b) Each scatterplot shows the model reliance (MR) score for each predictor for the best model for each of the subpopulations of female (x-axis) and male (y-axis) patients and each learning task; see Figure <a href="gender.html#fig:09-mr-legend">9.1</a>. Variables among the top 10 highest-ranked variables by MR in the F_model (red-violet), M_model (blue), or both models (yellow) are highlighted. alat_s_s0: alanine aminotransferase (ALAT) concentration; antihyp_s0_1: antihypertensive medication; crea_s_s0: serum creatinine concentration; diabp_s0: diastolic blood pressure; ferri_s0: ferritin concentration; gx_rs11597086_2: genetic marker associated with ALAT concentration <span class="citation"><a href="references.html#ref-yuan2008population" role="doc-biblioref">[116]</a></span>; heartr_s0: heart rate; hrs_s_s0: serum uric acid concentration; mcs_sf12_s0: SF-12 Physical and Mental Health Summary Scale <span class="citation"><a href="references.html#ref-bullinger1995german" role="doc-biblioref">[298]</a></span>; metsyn_s0_1: metabolic syndrome; rlegs_s0_1: restless legs syndrome; sleepp_s0_1: sleep problems; smoking_s0_1: ex-smoker; som_bmi_s0: body mass index; som_tail_s0: waist circumference; tg_s_s0: serum triglycerides concentration; waiidf_s0_1: increased waist circumference; whratc_s0_1: waist to hip ratio.
</p>
</div>

<!-- Asterisks signify models with significantly better cross-validation performance compared to the baseline with respect to RMSE using independent left-tailed Student's t-test with \[\alpha\] = 0.05. -->
<div class="inline-table"><table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'>
<caption>
<span id="tab:09-performance-5">Table 9.5: </span><strong>Regression model performance (LT 5a, LT 5b).</strong> Performance values are cross-validation mean ± standard deviation. The best performance for each measure is highlighted in bold.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
LT 5a (female)
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; font-weight: bold; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
LT 5b (male)
</div>
</th>
</tr>
<tr>
<th style="text-align:left;font-weight: bold;">
Algorithm
</th>
<th style="text-align:right;font-weight: bold;">
RMSE
</th>
<th style="text-align:right;font-weight: bold;">
R²
</th>
<th style="text-align:right;font-weight: bold;">
RMSE
</th>
<th style="text-align:right;font-weight: bold;">
R²
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
LASSO
</td>
<td style="text-align:right;">
<b>5.76 ± 1.05</b>
</td>
<td style="text-align:right;">
<b>0.23 ± 0.12</b>
</td>
<td style="text-align:right;">
6.18 ± 1.18
</td>
<td style="text-align:right;">
0.16 ± 0.22
</td>
</tr>
<tr>
<td style="text-align:left;">
Ridge
</td>
<td style="text-align:right;">
5.89 ± 1.09
</td>
<td style="text-align:right;">
0.20 ± 0.11
</td>
<td style="text-align:right;">
6.39 ± 1.13
</td>
<td style="text-align:right;">
0.11 ± 0.17
</td>
</tr>
<tr>
<td style="text-align:left;">
SVM
</td>
<td style="text-align:right;">
6.03 ± 1.09
</td>
<td style="text-align:right;">
0.17 ± 0.13
</td>
<td style="text-align:right;">
6.76 ± 1.29
</td>
<td style="text-align:right;">
0.02 ± 0.09
</td>
</tr>
<tr>
<td style="text-align:left;">
RF
</td>
<td style="text-align:right;">
5.88 ± 1.06
</td>
<td style="text-align:right;">
0.20 ± 0.10
</td>
<td style="text-align:right;">
6.18 ± 1.06
</td>
<td style="text-align:right;">
0.16 ± 0.17
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 1px solid #cdd0d4;">
GBT
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
6.02 ± 0.88
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
0.14 ± 0.16
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>6.02 ± 1.11</b>
</td>
<td style="text-align:right;border-bottom: 1px solid #cdd0d4;">
<b>0.20 ± 0.16</b>
</td>
</tr>
<tr>
<td style="text-align:left;font-style: italic;">
Baseline
</td>
<td style="text-align:right;font-style: italic;">
6.48 ± 1.04
</td>
<td style="text-align:right;font-style: italic;">
0.00 ± 0.00
</td>
<td style="text-align:right;font-style: italic;">
6.71 ± 1.21
</td>
<td style="text-align:right;font-style: italic;">
0.00 ± 0.00
</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="gender-conclusion" class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> Conclusion<a class="anchor" aria-label="anchor" href="#gender-conclusion"><i class="fas fa-link"></i></a>
</h2>
<p>We have presented a workflow to juxtapose the most important predictors between two a priori defined subpopulations based on black-box models.
We have adapted model reliance to estimate a feature’s attribution regarding the model and to investigate subpopulation-specific differences in this respect.
Compared to the workflow in Chapter <a href="iml.html#iml">8</a>, our goal was not to find a parsimonious model; hence we did not perform feature selection.</p>
<p>Our goals are related to <em>causal inference</em>, which aims to measure the true, <em>unconfounded</em> effect between variables.
Current efforts include building methods to detect causal relationships in observational data <span class="citation"><a href="references.html#ref-Pearl:BookOfWhy2018" role="doc-biblioref">[299]</a>, <a href="references.html#ref-scholkopf2019causality" role="doc-biblioref">[300]</a></span>, opposed to a randomized clinical trial (RCT) in clinical research.
RCTs are considered the gold standard for inferring causal effects of treatment <span class="citation"><a href="references.html#ref-hariton2018" role="doc-biblioref">[36]</a></span>.
In an RCT, individual patients of a patient population are randomly assigned to one of two subgroups: a <em>treatment</em> subgroup and a <em>control</em> subgroup.
Only the former receives the treatment.
Randomization of subgroup membership serves to minimize the effects of potential confounders and selection bias.
The two subgroups are as similar as possible before the intervention so that it is possible to calculate the <em>average treatment effect</em> to quantify the true causal efficacy of the treatment <span class="citation"><a href="references.html#ref-Hernan:CausalityBook2020" role="doc-biblioref">[301]</a></span>.
Translated to our application, an appropriate causality question is: <em>What is the effect of gender on tinnitus severity and depression?</em>
However, our goal was different: we wanted to exploratively examine similarities and differences between subpopulations regarding factors that are predictive of a response of interest.
Thus, we were interested not only in the relationship of gender on the response, but also in differences between the female and male subpopulations in the predictability of other variables on the response.
With the generation of new hypotheses as the main goal in mind, our focus is on providing exploratory methods for comparing differences between predefined subpopulations.</p>

</div>
</div>



  <div class="chapter-nav">
<div class="prev"><a href="iml.html"><span class="header-section-number">8</span> Post-Hoc Interpretation of Classification Models</a></div>
<div class="next"><a href="conclusion.html"><span class="header-section-number">10</span> Summary and Future Work</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#gender"><span class="header-section-number">9</span> Subpopulation-Specific Learning and Post-Hoc Model Interpretation</a></li>
<li><a class="nav-link" href="#gender-intro"><span class="header-section-number">9.1</span> Motivation and Comparison to Related Work</a></li>
<li><a class="nav-link" href="#gender-workflow"><span class="header-section-number">9.2</span> Workflow</a></li>
<li><a class="nav-link" href="#gender-measure"><span class="header-section-number">9.3</span> Comparing Differences in Feature Importance between Two Subpopulations</a></li>
<li><a class="nav-link" href="#gender-learning-tasks"><span class="header-section-number">9.4</span> Learning Tasks and Evaluation Setup</a></li>
<li>
<a class="nav-link" href="#gender-results"><span class="header-section-number">9.5</span> Validation on Two Datasets</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#results-for-cha"><span class="header-section-number">9.5.1</span> Results for CHA</a></li>
<li><a class="nav-link" href="#results-for-ship"><span class="header-section-number">9.5.2</span> Results for SHIP</a></li>
</ul>
</li>
<li><a class="nav-link" href="#gender-conclusion"><span class="header-section-number">9.6</span> Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Intelligent Assistance for Expert-Driven Subpopulation Discovery in High-Dimensional Timestamped Medical Data</strong>" was written by Uli Niemann. It was last built on 09.03.2021.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
